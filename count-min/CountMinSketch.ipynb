{
 "metadata": {
  "name": "",
  "signature": "sha256:469285e7d235d84f6d806ae277b686f47e67e1b6e717692769251a10e89e4b24"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Basic Idea of Count Min sketch"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We map the input value to _multiple_ points in a _relatively small_ output space. Therefore, the count associated with a given input will be applied to multiple counts in the output space. Even though collisions will occur, the _minimum_ count associated with a given input will have some desirable properties, including the ability to be used to estimate the largest N counts.\n",
      "\n",
      "<img src=\"files/count_min_2.png\">\n",
      "\n",
      "http://debasishg.blogspot.com/2014/01/count-min-sketch-data-structure-for.html\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Parameters of the sketch:\n",
      "\n",
      "*   epsilon\n",
      "*   delta\n",
      "\n",
      "These parameters are inversely and exponentially (respectively) related to the sketch size parameters, d and w. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Implementation of the CM sketch"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import random\n",
      "import numpy as np\n",
      "import heapq\n",
      "import json\n",
      "import time\n",
      "\n",
      "BIG_PRIME = 9223372036854775783\n",
      "\n",
      "def random_parameter():\n",
      "    return random.randrange(0, BIG_PRIME - 1)\n",
      "\n",
      "\n",
      "class Sketch:\n",
      "    def __init__(self, delta, epsilon, k):\n",
      "        \"\"\"\n",
      "        Setup a new count-min sketch with parameters delta, epsilon and k\n",
      "\n",
      "        The parameters delta and epsilon control the accuracy of the\n",
      "        estimates of the sketch\n",
      "\n",
      "        Cormode and Muthukrishnan prove that for an item i with count a_i, the\n",
      "        estimate from the sketch a_i_hat will satisfy the relation\n",
      "\n",
      "        a_hat_i <= a_i + epsilon * ||a||_1\n",
      "\n",
      "        with probability at least 1 - delta, where a is the the vector of all\n",
      "        all counts and ||x||_1 is the L1 norm of a vector x\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        delta : float\n",
      "            A value in the unit interval that sets the precision of the sketch\n",
      "        epsilon : float\n",
      "            A value in the unit interval that sets the precision of the sketch\n",
      "        k : int\n",
      "            A positive integer that sets the number of top items counted\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> s = Sketch(10**-7, 0.005, 40)\n",
      "\n",
      "        Raises\n",
      "        ------\n",
      "        ValueError\n",
      "            If delta or epsilon are not in the unit interval, or if k is\n",
      "            not a positive integer\n",
      "\n",
      "        \"\"\"\n",
      "        if delta <= 0 or delta >= 1:\n",
      "            raise ValueError(\"delta must be between 0 and 1, exclusive\")\n",
      "        if epsilon <= 0 or epsilon >= 1:\n",
      "            raise ValueError(\"epsilon must be between 0 and 1, exclusive\")\n",
      "        if k < 1:\n",
      "            raise ValueError(\"k must be a positive integer\")\n",
      "\n",
      "        self.w = int(np.ceil(np.exp(1) / epsilon))\n",
      "        self.d = int(np.ceil(np.log(1 / delta)))\n",
      "        self.k = k\n",
      "        self.hash_functions = [self.__generate_hash_function() for i in range(self.d)]\n",
      "        self.count = np.zeros((self.d, self.w), dtype='int32')\n",
      "        self.heap, self.top_k = [], {} # top_k => [estimate, key] pairs\n",
      "\n",
      "    def update(self, key, increment):\n",
      "        \"\"\"\n",
      "        Updates the sketch for the item with name of key by the amount\n",
      "        specified in increment\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        key : string\n",
      "            The item to update the value of in the sketch\n",
      "        increment : integer\n",
      "            The amount to update the sketch by for the given key\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> s = Sketch(10**-7, 0.005, 40)\n",
      "        >>> s.update('http://www.cnn.com/', 1)\n",
      "\n",
      "        \"\"\"\n",
      "        for row, hash_function in enumerate(self.hash_functions):\n",
      "            column = hash_function(abs(hash(key)))\n",
      "            self.count[row, column] += increment\n",
      "\n",
      "        self.update_heap(key)\n",
      "\n",
      "    def update_heap(self, key):\n",
      "        \"\"\"\n",
      "        Updates the class's heap that keeps track of the top k items for a\n",
      "        given key\n",
      "\n",
      "        For the given key, it checks whether the key is present in the heap,\n",
      "        updating accordingly if so, and adding it to the heap if it is\n",
      "        absent\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        key : string\n",
      "            The item to check against the heap\n",
      "\n",
      "        \"\"\"\n",
      "        estimate = self.get(key)\n",
      "\n",
      "        if not self.heap or estimate >= self.heap[0][0]:\n",
      "            if key in self.top_k:\n",
      "                old_pair = self.top_k.get(key)\n",
      "                old_pair[0] = estimate\n",
      "                heapq.heapify(self.heap)\n",
      "            else:\n",
      "                if len(self.top_k) < self.k:\n",
      "                    heapq.heappush(self.heap, [estimate, key])\n",
      "                    self.top_k[key] = [estimate, key]\n",
      "                else:\n",
      "                    new_pair = [estimate, key]\n",
      "                    old_pair = heapq.heappushpop(self.heap, new_pair)\n",
      "                    del self.top_k[old_pair[1]]\n",
      "                    self.top_k[key] = new_pair\n",
      "\n",
      "    def get(self, key):\n",
      "        \"\"\"\n",
      "        Fetches the sketch estimate for the given key\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        key : string\n",
      "            The item to produce an estimate for\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        estimate : int\n",
      "            The best estimate of the count for the given key based on the\n",
      "            sketch\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> s = Sketch(10**-7, 0.005, 40)\n",
      "        >>> s.update('http://www.cnn.com/', 1)\n",
      "        >>> s.get('http://www.cnn.com/')\n",
      "        1\n",
      "\n",
      "        \"\"\"\n",
      "        value = sys.maxint\n",
      "        for row, hash_function in enumerate(self.hash_functions):\n",
      "            column = hash_function(abs(hash(key)))\n",
      "            value = min(self.count[row, column], value)\n",
      "\n",
      "        return value\n",
      "\n",
      "    def __generate_hash_function(self):\n",
      "        \"\"\"\n",
      "        Returns a hash function from a family of pairwise-independent hash\n",
      "        functions\n",
      "\n",
      "        \"\"\"\n",
      "        a, b = random_parameter(), random_parameter()\n",
      "        return lambda x: (a * x + b) % BIG_PRIME % self.w\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define a function to return a list of the exact top users, sorted by count\n",
      "def exact_top_users(f, top_n = 10):\n",
      "    import operator\n",
      "    counts = {}\n",
      "    for line in f:\n",
      "        try:\n",
      "            user = json.loads(line)['actor']['preferredUsername']\n",
      "            if user not in counts:\n",
      "                counts[user] = 1\n",
      "            else:\n",
      "                counts[user] += 1\n",
      "        except ValueError:\n",
      "            pass\n",
      "        except KeyError:\n",
      "            pass\n",
      "    counter = 0\n",
      "    results = []\n",
      "    for user,count in reversed(sorted(counts.iteritems(), key=operator.itemgetter(1))):\n",
      "        if counter >= top_n:\n",
      "            break\n",
      "        results.append('{} {}'.format(user,str(count)))\n",
      "        counter += 1\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('CM_small.json')\n",
      "results_exact = sorted(exact_top_users(f))\n",
      "print(results_exact)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['HPSupport 3', 'user1 3', 'user2 3', 'user4 1']\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define a function to return a list of the estimated top users, sorted by count\n",
      "def CM_top_users(f, s):\n",
      "    for line in f:\n",
      "        try:\n",
      "            user_name = json.loads(line)['actor']['preferredUsername']\n",
      "            s.update(user_name,1)\n",
      "        except ValueError:\n",
      "            pass\n",
      "        except KeyError:\n",
      "            pass\n",
      "    \n",
      "    results = []\n",
      "    for value in reversed(sorted(s.top_k.values())):\n",
      "        results.append('{1} {0}'.format(str(value[0]),str(value[1])))\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# instantiate a Sketch object\n",
      "s = Sketch(10**-3, 0.1, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('CM_small.json')\n",
      "results_CM = sorted(CM_top_users(f,s))\n",
      "print(results_CM)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['HPSupport 6', 'user1 6', 'user2 6', 'user4 2']\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for item in zip(results_exact,results_CM):\n",
      "    print(item)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('HPSupport 3', 'HPSupport 6')\n",
        "('user1 3', 'user1 6')\n",
        "('user2 3', 'user2 6')\n",
        "('user4 1', 'user4 2')\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Is it possible to make the sketchs so coarse that its estimates are wrong even for this data set?\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = Sketch(0.9, 0.9, 10)\n",
      "f = open('CM_small.json')\n",
      "results_coarse_CM = CM_top_users(f,s)\n",
      "print(results_coarse_CM)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['user2 6', 'HPSupport 5', 'user1 3', 'user4 1']\n"
       ]
      }
     ],
     "prompt_number": 182
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Yes! (if you try enough) Why? \n",
      "\n",
      "* The 'w' parameter goes like ceiling(exp(1)/epsilon), which is always >=~ 3.\n",
      "* The 'd' parameter goes like ceiling(log(1/delta), which is always >= 1.\n",
      "\n",
      "So, you're dealing with a space with minimum size 3 x 1. With 10 records, it's possible that all 4 users map their counts to the point. So it's possible to see an estimate as high as 10, in this case."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Now for a larger data set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('CM_large.json')\n",
      "%time results_exact = exact_top_users(f)\n",
      "print(results_exact)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 18.6 s, sys: 255 ms, total: 18.9 s\n",
        "Wall time: 19 s\n",
        "['ryuutuu19 39', 'jidousya_ 29', 'food_nourin 27', 'life_style_s 26', 'punpun4 25', 'SportsAB 25', 'fudousankensetu 22', 'TaylorMadeGolf 17', '333_shy 15', 'FuckMica_ 14']\n"
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('CM_large.json')\n",
      "s = Sketch(10**-4, 0.001, 10)\n",
      "%time results_CM = CM_top_users(f,s)\n",
      "print(results_CM)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 40.1 s, sys: 222 ms, total: 40.4 s\n",
        "Wall time: 40.3 s\n",
        "['ryuutuu19 82', 'food_nourin 72', 'life_style_s 70', 'jidousya_ 69', 'SportsAB 67', '333_shy 62', 'fudousankensetu 61', 'punpun4 59', 'TaylorMadeGolf 59', 'FuckMica_ 58']\n"
       ]
      }
     ],
     "prompt_number": 185
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For this precision and dataset size, the CM algo takes _longer_ than the exact solution. How's the accuracy?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for item in zip(results_exact,results_CM):\n",
      "    print(item)\n",
      "    print item[1] in results_exact and item[0] in results_CM"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('ryuutuu19 39', 'yuki_kkth 538')\n",
        "False\n",
        "('jidousya_ 29', 'georgiaa_wbuu 531')\n",
        "False\n",
        "('food_nourin 27', '_MahlonDallee 529')\n",
        "False\n",
        "('life_style_s 26', 'daniel_leparulo 527')\n",
        "False\n",
        "('punpun4 25', 'Carla_Carpediem 525')\n",
        "False\n",
        "('SportsAB 25', 'viishthay 523')\n",
        "False\n",
        "('fudousankensetu 22', 'YOLOfonseca 521')\n",
        "False\n",
        "('TaylorMadeGolf 17', 'cautiouX 520')\n",
        "False\n",
        "('333_shy 15', 'Ana_Bia147 520')\n",
        "False\n",
        "('FuckMica_ 14', 'AdrianaCelis7 520')\n",
        "False\n"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('CM_large.json')\n",
      "s = Sketch(10**-3, 0.01, 10)\n",
      "%time results_CM = CM_top_users(f,s)\n",
      "print(results_CM)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 35.9 s, sys: 254 ms, total: 36.1 s\n",
        "Wall time: 36.1 s\n",
        "['yuki_kkth 538', 'georgiaa_wbuu 531', '_MahlonDallee 529', 'daniel_leparulo 527', 'Carla_Carpediem 525', 'viishthay 523', 'YOLOfonseca 521', 'cautiouX 520', 'Ana_Bia147 520', 'AdrianaCelis7 520']\n"
       ]
      }
     ],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for item in zip(results_exact,results_CM):\n",
      "    print(item)\n",
      "    print item[1] in results_exact and item[0] in results_CM"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('ryuutuu19 39', 'yuki_kkth 538')\n",
        "False\n",
        "('jidousya_ 29', 'georgiaa_wbuu 531')\n",
        "False\n",
        "('food_nourin 27', '_MahlonDallee 529')\n",
        "False\n",
        "('life_style_s 26', 'daniel_leparulo 527')\n",
        "False\n",
        "('punpun4 25', 'Carla_Carpediem 525')\n",
        "False\n",
        "('SportsAB 25', 'viishthay 523')\n",
        "False\n",
        "('fudousankensetu 22', 'YOLOfonseca 521')\n",
        "False\n",
        "('TaylorMadeGolf 17', 'cautiouX 520')\n",
        "False\n",
        "('333_shy 15', 'Ana_Bia147 520')\n",
        "False\n",
        "('FuckMica_ 14', 'AdrianaCelis7 520')\n",
        "False\n"
       ]
      }
     ],
     "prompt_number": 191
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The most common use of the CM sketch is analysis of streaming data. Why?\n",
      "\n",
      "* Becasue the data are arriving in real time, the hashing of the inputs is not a bottleneck as it is when the data are already collected.\n",
      "* The sketches are associative, meaning that the operation can be parallelized trivially, and the results easily combined in the end.\n",
      "\n",
      "This will be a primary function of the Enumerator, which will be demo-ed soon."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}